use anyhow::{Context, Result};
use chrono::{DateTime, Datelike, FixedOffset, Timelike, Utc};
use reqwest::{header::HeaderMap, StatusCode};
use serde::{Deserialize, Serialize};
use std::cmp::min;
use std::time::{Duration, SystemTime, UNIX_EPOCH};
use tokio::time::sleep;

use crate::api::http;
use crate::models::{
    ContributionCalendar, ContributionDay, ContributionWeek, PinnedRepo, TimeDistribution,
    UserStats,
};

// Include GraphQL queries generated by build.rs from .graphql files
include!(concat!(env!("OUT_DIR"), "/queries.rs"));

/// Implements [[RFC-0002:C-GRAPHQL-CLIENT]]
#[derive(Clone)]
pub struct GraphQLClient {
    client: reqwest::Client,
    pinned_repos: Vec<(String, String)>, // (owner, name) pairs
    timezone_offset: FixedOffset,        // User's timezone for time distribution
}

const GRAPHQL_ENDPOINT: &str = "https://api.github.com/graphql";
const REST_API_BASE: &str = "https://api.github.com";
const GRAPHQL_REPOS_PAGE_SIZE: usize = 100;
const REST_COMMITS_PAGE_SIZE: usize = 100;
const REST_COMMITS_MAX_PAGES: u32 = 10;
const RETRY_MAX_ATTEMPTS: usize = 3;
const RETRY_BASE_DELAY_MS: u64 = 500;
const RETRY_MAX_DELAY_MS: u64 = 5000;

#[derive(Debug, Serialize)]
struct GraphQLRequest<'a> {
    query: &'a str,
    variables: serde_json::Value,
}

// ===== User query response types =====

#[derive(Debug, Deserialize)]
struct UserResponse {
    data: Option<UserDataRoot>,
    errors: Option<Vec<GraphQLError>>,
}

#[derive(Debug, Deserialize)]
struct GraphQLError {
    message: String,
}

#[derive(Debug, Deserialize)]
struct UserDataRoot {
    user: Option<UserNode>,
}

#[derive(Debug, Deserialize)]
#[serde(rename_all = "camelCase")]
struct UserNode {
    id: String, // GitHub node ID for author filtering
    name: Option<String>,
    login: String,
    bio: Option<String>,
    company: Option<String>,
    location: Option<String>,
    website_url: Option<String>,
    twitter_username: Option<String>,
    avatar_url: Option<String>,
    created_at: DateTime<Utc>,
    followers: CountNode,
    organizations: CountNode,
    repositories: RepositoriesNode,
    contributions_collection: ContributionsCollectionNode,
}

#[derive(Debug, Deserialize)]
#[serde(rename_all = "camelCase")]
struct CountNode {
    total_count: u64,
}

#[derive(Debug, Deserialize)]
#[serde(rename_all = "camelCase")]
struct RepositoriesNode {
    total_count: u64,
    nodes: Vec<RepoStatsNode>,
    page_info: PageInfoNode,
}

#[derive(Debug, Deserialize)]
#[serde(rename_all = "camelCase")]
struct RepoStatsNode {
    stargazer_count: u64,
    fork_count: u64,
}

#[derive(Debug, Deserialize, Clone)]
#[serde(rename_all = "camelCase")]
struct PageInfoNode {
    has_next_page: bool,
    end_cursor: Option<String>,
}

#[derive(Debug, Deserialize)]
#[serde(rename_all = "camelCase")]
struct ContributionsCollectionNode {
    total_commit_contributions: u64,
    total_pull_request_contributions: u64,
    total_issue_contributions: u64,
    total_repository_contributions: u64,
    restricted_contributions_count: u64,
    contribution_years: Vec<i32>,
    first_issue_contribution: Option<FirstContributionNode>,
    first_pull_request_contribution: Option<FirstContributionNode>,
    first_repository_contribution: Option<FirstContributionNode>,
    contribution_calendar: CalendarNode,
}

#[derive(Debug, Deserialize)]
#[serde(rename_all = "camelCase")]
struct FirstContributionNode {
    occurred_at: DateTime<Utc>,
}

#[derive(Debug, Deserialize)]
#[serde(rename_all = "camelCase")]
struct CalendarNode {
    total_contributions: u64,
    weeks: Vec<WeekNode>,
}

#[derive(Debug, Deserialize)]
#[serde(rename_all = "camelCase")]
struct WeekNode {
    contribution_days: Vec<DayNode>,
}

#[derive(Debug, Deserialize)]
#[serde(rename_all = "camelCase")]
struct DayNode {
    date: String,
    contribution_count: u64,
    contribution_level: String,
}

// ===== Repo query response types =====

#[derive(Debug, Deserialize)]
struct RepoResponse {
    data: Option<RepoDataRoot>,
    errors: Option<Vec<GraphQLError>>,
}

#[derive(Debug, Deserialize)]
struct RepoDataRoot {
    repository: Option<RepoNode>,
}

#[derive(Debug, Deserialize)]
#[serde(rename_all = "camelCase")]
struct RepoNode {
    name: String,
    description: Option<String>,
    stargazer_count: u64,
    fork_count: u64,
    is_archived: bool,
    is_fork: bool,
    is_template: bool,
    disk_usage: u64,
    watchers: CountNode,
    issues: CountNode,
    pull_requests: CountNode,
    releases: CountNode,
    license_info: Option<LicenseNode>,
    repository_topics: RepositoryTopicsNode,
    primary_language: Option<LanguageNode>,
    default_branch_ref: Option<DefaultBranchRefNode>,
}

#[derive(Debug, Deserialize)]
struct LanguageNode {
    name: String,
    color: Option<String>,
}

#[derive(Debug, Deserialize)]
struct DefaultBranchRefNode {
    name: String,
    target: CommitTarget,
}

#[derive(Debug, Deserialize)]
#[serde(rename_all = "camelCase")]
struct LicenseNode {
    spdx_id: Option<String>,
}

#[derive(Debug, Deserialize)]
#[serde(rename_all = "camelCase")]
struct RepositoryTopicsNode {
    nodes: Vec<RepositoryTopicNode>,
}

#[derive(Debug, Deserialize)]
#[serde(rename_all = "camelCase")]
struct RepositoryTopicNode {
    topic: TopicNode,
}

#[derive(Debug, Deserialize)]
#[serde(rename_all = "camelCase")]
struct TopicNode {
    name: String,
}

#[derive(Debug, Deserialize)]
#[serde(rename_all = "camelCase")]
struct CommitTarget {
    history: Option<HistoryNode>,
}

#[derive(Debug, Deserialize)]
#[serde(rename_all = "camelCase")]
struct HistoryNode {
    nodes: Vec<CommitNode>,
    total_count: u64,
}

#[derive(Debug, Deserialize)]
#[serde(rename_all = "camelCase")]
struct CommitNode {
    committed_date: DateTime<Utc>,
    additions: u64,
    deletions: u64,
}

impl GraphQLClient {
    /// Create a new GraphQL client
    /// `pinned_repos_str` is a comma-separated list of "owner/repo" pairs
    /// `timezone_str` is an offset like "+08:00" or "-05:00" (default: "+00:00")
    pub fn new(
        token: String,
        pinned_repos_str: Option<String>,
        timezone_str: Option<String>,
    ) -> Self {
        let client = http::build_github_client(&token)
            .unwrap_or_else(|e| panic!("failed to build HTTP client: {e:#}"));
        let pinned_repos = pinned_repos_str
            .unwrap_or_default()
            .split(',')
            .filter_map(|s| {
                let s = s.trim();
                if s.is_empty() {
                    return None;
                }
                let parts: Vec<&str> = s.splitn(2, '/').collect();
                if parts.len() == 2 {
                    Some((parts[0].to_string(), parts[1].to_string()))
                } else {
                    eprintln!("warning: invalid pinned repo format: {s} (expected owner/repo)");
                    None
                }
            })
            .collect();

        // Parse timezone offset (e.g., "+08:00", "-05:00")
        let timezone_offset = parse_timezone_offset(timezone_str.as_deref());

        Self {
            client,
            pinned_repos,
            timezone_offset,
        }
    }

    /// Fetch all user stats via GraphQL
    /// Implements [[RFC-0002:C-GRAPHQL-CLIENT]]
    pub async fn fetch_stats(&self, username: &str) -> Result<UserStats> {
        let now = Utc::now();
        let one_year_ago = now - chrono::Duration::days(365);

        let user = self
            .fetch_user_with_repos(username, &one_year_ago, &now)
            .await?;

        let (total_stars, total_forks) = self.compute_repo_totals(&user.repositories.nodes);
        let (age_years, age_days) = self.compute_account_age(now, user.created_at);
        let calendar = self.build_calendar(&user.contributions_collection);
        let streaks = calendar.compute_streaks();
        let pinned_repos = self
            .fetch_pinned_repos(&one_year_ago, &user.id)
            .await;
        let time_distribution = self.fetch_time_distribution_optional(&user.login).await;
        let (first_issue, first_pr, first_repo) =
            self.first_contributions(&user.contributions_collection);

        Ok(UserStats {
            name: user.name,
            username: user.login,
            bio: user.bio,
            company: user.company,
            location: user.location,
            website_url: user.website_url,
            twitter_username: user.twitter_username,
            avatar_url: user.avatar_url,
            organizations: Some(user.organizations.total_count),
            repos: user.repositories.total_count,
            stars: total_stars,
            forks: total_forks,
            followers: user.followers.total_count,
            commits: user.contributions_collection.total_commit_contributions,
            prs: user
                .contributions_collection
                .total_pull_request_contributions,
            issues: user.contributions_collection.total_issue_contributions,
            total_repository_contributions: Some(
                user.contributions_collection.total_repository_contributions,
            ),
            restricted_contributions: Some(
                user.contributions_collection.restricted_contributions_count,
            ),
            contribution_years: Some(user.contributions_collection.contribution_years),
            first_issue_contribution: first_issue,
            first_pull_request_contribution: first_pr,
            first_repository_contribution: first_repo,
            account_age_years: age_years,
            account_age_days: age_days,
            contribution_calendar: Some(calendar),
            streaks: Some(streaks),
            pinned_repos,
            time_distribution,
        })
    }

    fn compute_repo_totals(&self, repos: &[RepoStatsNode]) -> (u64, u64) {
        let stars = repos.iter().map(|r| r.stargazer_count).sum();
        let forks = repos.iter().map(|r| r.fork_count).sum();
        (stars, forks)
    }

    fn compute_account_age(&self, now: DateTime<Utc>, created_at: DateTime<Utc>) -> (u64, u64) {
        let age = now.signed_duration_since(created_at);
        let age_days = age.num_days().max(0) as u64;
        let age_years = age_days / 365;
        (age_years, age_days)
    }

    fn build_calendar(
        &self,
        collection: &ContributionsCollectionNode,
    ) -> ContributionCalendar {
        ContributionCalendar {
            total_contributions: collection.contribution_calendar.total_contributions,
            weeks: collection
                .contribution_calendar
                .weeks
                .iter()
                .map(|w| ContributionWeek {
                    days: w
                        .contribution_days
                        .iter()
                        .map(|d| ContributionDay {
                            date: d.date.clone(),
                            contribution_count: d.contribution_count,
                            level: level_from_string(&d.contribution_level),
                        })
                        .collect(),
                })
                .collect(),
        }
    }

    fn first_contributions(
        &self,
        collection: &ContributionsCollectionNode,
    ) -> (Option<String>, Option<String>, Option<String>) {
        let first_issue = collection
            .first_issue_contribution
            .as_ref()
            .map(|c| c.occurred_at.format("%Y-%m-%d").to_string());
        let first_pr = collection
            .first_pull_request_contribution
            .as_ref()
            .map(|c| c.occurred_at.format("%Y-%m-%d").to_string());
        let first_repo = collection
            .first_repository_contribution
            .as_ref()
            .map(|c| c.occurred_at.format("%Y-%m-%d").to_string());
        (first_issue, first_pr, first_repo)
    }

    async fn fetch_user_with_repos(
        &self,
        username: &str,
        from: &DateTime<Utc>,
        to: &DateTime<Utc>,
    ) -> Result<UserNode> {
        let mut repo_after: Option<String> = None;
        let mut combined: Option<UserNode> = None;

        loop {
            let page = self
                .fetch_user_page(username, from, to, repo_after.as_deref())
                .await?;
            if let Some(ref mut user) = combined {
                merge_repository_page(&mut user.repositories, page.repositories);
            } else {
                combined = Some(page);
            }

            let page_info = combined
                .as_ref()
                .map(|u| u.repositories.page_info.clone())
                .unwrap();
            if !page_info.has_next_page {
                break;
            }
            repo_after = page_info.end_cursor;
            if repo_after.is_none() {
                break;
            }
        }

        combined.context("User not found")
    }

    async fn fetch_user_page(
        &self,
        username: &str,
        from: &DateTime<Utc>,
        to: &DateTime<Utc>,
        repo_after: Option<&str>,
    ) -> Result<UserNode> {
        let variables = serde_json::json!({
            "login": username,
            "from": from.to_rfc3339(),
            "to": to.to_rfc3339(),
            "repoAfter": repo_after,
            "repoFirst": GRAPHQL_REPOS_PAGE_SIZE,
        });

        let request = GraphQLRequest {
            query: USER_QUERY,
            variables,
        };

        let response = send_with_retry(
            || self.client.post(GRAPHQL_ENDPOINT).json(&request),
            "GraphQL user request",
        )
        .await?;

        let gql_response: UserResponse = response
            .json()
            .await
            .context("Failed to parse user GraphQL response")?;

        if let Some(errors) = gql_response.errors {
            let msgs: Vec<_> = errors.iter().map(|e| e.message.as_str()).collect();
            anyhow::bail!("GraphQL errors: {}", msgs.join(", "));
        }

        gql_response
            .data
            .and_then(|d| d.user)
            .context("User not found")
    }

    async fn fetch_pinned_repos(
        &self,
        since: &DateTime<Utc>,
        author_id: &str,
    ) -> Option<Vec<PinnedRepo>> {
        if self.pinned_repos.is_empty() {
            return None;
        }

        let mut join_set = tokio::task::JoinSet::new();
        for (owner, name) in &self.pinned_repos {
            let client = self.clone();
            let owner = owner.clone();
            let name = name.clone();
            let since = *since;
            let author_id = author_id.to_string();
            join_set.spawn(async move {
                client
                    .fetch_repo(&owner, &name, &since, &author_id)
                    .await
            });
        }

        let mut repos = Vec::new();
        while let Some(result) = join_set.join_next().await {
            match result {
                Ok(Ok(repo)) => repos.push(repo),
                Ok(Err(e)) => eprintln!("warning: failed to fetch pinned repo: {e:#}"),
                Err(e) => eprintln!("warning: failed to join pinned repo task: {e:#}"),
            }
        }

        if repos.is_empty() { None } else { Some(repos) }
    }

    async fn fetch_time_distribution_optional(
        &self,
        username: &str,
    ) -> Option<TimeDistribution> {
        match self.fetch_time_distribution(username).await {
            Ok(dist) => Some(dist),
            Err(e) => {
                eprintln!("warning: failed to fetch time distribution: {e:#}");
                None
            }
        }
    }

    async fn fetch_repo(
        &self,
        owner: &str,
        name: &str,
        since: &DateTime<Utc>,
        author_id: &str,
    ) -> Result<PinnedRepo> {
        let variables = serde_json::json!({
            "owner": owner,
            "name": name,
            "since": since.to_rfc3339(),
            "authorId": author_id,
        });

        let request = GraphQLRequest {
            query: REPO_QUERY,
            variables,
        };

        let response = send_with_retry(
            || self.client.post(GRAPHQL_ENDPOINT).json(&request),
            "GraphQL repo request",
        )
        .await?;

        let gql_response: RepoResponse = response
            .json()
            .await
            .context("Failed to parse repo GraphQL response")?;

        if let Some(errors) = gql_response.errors {
            let msgs: Vec<_> = errors.iter().map(|e| e.message.as_str()).collect();
            anyhow::bail!("GraphQL errors: {}", msgs.join(", "));
        }

        let repo = gql_response
            .data
            .and_then(|d| d.repository)
            .context("Repository not found")?;

        let (additions, deletions, commits, last_date) =
            if let Some(ref branch) = repo.default_branch_ref {
                let history = branch.target.history.as_ref();
                let adds: u64 = history
                    .map(|h| h.nodes.iter().map(|c| c.additions).sum())
                    .unwrap_or(0);
                let dels: u64 = history
                    .map(|h| h.nodes.iter().map(|c| c.deletions).sum())
                    .unwrap_or(0);
                let count = history.map(|h| h.total_count).unwrap_or(0);
                // Get user's last commit date from the first node (most recent)
                let date = history
                    .and_then(|h| h.nodes.first())
                    .map(|c| c.committed_date.format("%Y-%m-%d").to_string());
                (adds, dels, count, date)
            } else {
                (0, 0, 0, None)
            };

        let topics: Vec<String> = repo
            .repository_topics
            .nodes
            .iter()
            .map(|n| n.topic.name.clone())
            .collect();
        let topics = if topics.is_empty() {
            None
        } else {
            Some(topics)
        };

        Ok(PinnedRepo {
            name: repo.name,
            description: repo.description,
            stars: repo.stargazer_count,
            forks: repo.fork_count,
            watchers: repo.watchers.total_count,
            issues: repo.issues.total_count,
            pull_requests: repo.pull_requests.total_count,
            releases: repo.releases.total_count,
            license: repo.license_info.and_then(|l| l.spdx_id),
            topics,
            language: repo.primary_language.as_ref().map(|l| l.name.clone()),
            language_color: repo.primary_language.and_then(|l| l.color),
            is_archived: repo.is_archived,
            is_fork: repo.is_fork,
            is_template: repo.is_template,
            disk_usage: repo.disk_usage,
            default_branch: repo.default_branch_ref.as_ref().map(|b| b.name.clone()),
            recent_additions: additions,
            recent_deletions: deletions,
            recent_commits: commits,
            last_commit_date: last_date,
        })
    }

    /// Fetch commit time distribution using REST API search
    /// Returns a 24Ã—7 grid of commit counts by hour and weekday
    async fn fetch_time_distribution(&self, username: &str) -> Result<TimeDistribution> {
        let tz_str = format!(
            "{:+03}:{:02}",
            self.timezone_offset.local_minus_utc() / 3600,
            (self.timezone_offset.local_minus_utc().abs() % 3600) / 60
        );
        let mut distribution = TimeDistribution::new(tz_str);

        // Track earliest and latest commit dates
        let mut earliest: Option<DateTime<FixedOffset>> = None;
        let mut latest: Option<DateTime<FixedOffset>> = None;

        // Fetch up to REST_COMMITS_MAX_PAGES * REST_COMMITS_PAGE_SIZE commits
        for page in 1..=REST_COMMITS_MAX_PAGES {
            let url = format!(
                "{}/search/commits?q=author:{}&sort=author-date&order=desc&per_page={}&page={}",
                REST_API_BASE, username, REST_COMMITS_PAGE_SIZE, page
            );

            let response = send_with_retry(
                || self.client.get(&url),
                "REST commit search",
            )
            .await?;

            let search_result: CommitSearchResponse = response
                .json()
                .await
                .context("Failed to parse commit search response")?;

            if search_result.items.is_empty() {
                break; // No more results
            }

            for item in &search_result.items {
                if let Some(ref commit) = item.commit
                    && let Some(ref author) = commit.author
                {
                    // Parse the date and convert to user's timezone
                    if let Ok(utc_time) = DateTime::parse_from_rfc3339(&author.date) {
                        let local_time = utc_time.with_timezone(&self.timezone_offset);
                        let hour = local_time.hour() as u8;
                        // weekday(): Mon=0, Tue=1, ..., Sun=6
                        let weekday = local_time.weekday().num_days_from_monday() as u8;
                        distribution.add(hour, weekday);

                        // Track date range
                        match earliest {
                            None => earliest = Some(local_time),
                            Some(e) if local_time < e => earliest = Some(local_time),
                            _ => {}
                        }
                        match latest {
                            None => latest = Some(local_time),
                            Some(l) if local_time > l => latest = Some(local_time),
                            _ => {}
                        }
                    }
                }
            }

            // If we got fewer than 100, we've reached the end
            if search_result.items.len() < REST_COMMITS_PAGE_SIZE {
                break;
            }
        }

        // Set date range
        distribution.earliest_date = earliest.map(|d| d.format("%Y-%m-%d").to_string());
        distribution.latest_date = latest.map(|d| d.format("%Y-%m-%d").to_string());

        distribution.finalize();
        Ok(distribution)
    }
}

fn parse_timezone_offset(input: Option<&str>) -> FixedOffset {
    input
        .and_then(|s| s.parse::<FixedOffset>().ok())
        .unwrap_or_else(|| FixedOffset::east_opt(0).unwrap())
}

fn merge_repository_page(target: &mut RepositoriesNode, page: RepositoriesNode) {
    target.nodes.extend(page.nodes);
    target.total_count = page.total_count;
    target.page_info = page.page_info;
}

async fn send_with_retry<F>(mut make_request: F, context: &str) -> Result<reqwest::Response>
where
    F: FnMut() -> reqwest::RequestBuilder,
{
    let mut attempt = 0;
    loop {
        let response = make_request().send().await;
        match response {
            Ok(resp) => {
                if resp.status().is_success() {
                    return Ok(resp);
                }

                if attempt < RETRY_MAX_ATTEMPTS && should_retry(resp.status(), resp.headers()) {
                    let wait = retry_delay(attempt, resp.status(), resp.headers());
                    sleep(wait).await;
                    attempt += 1;
                    continue;
                }

                let status = resp.status();
                let body = resp.text().await.unwrap_or_default();
                anyhow::bail!("{context} failed with status {status}: {body}");
            }
            Err(err) => {
                if attempt < RETRY_MAX_ATTEMPTS {
                    let wait = retry_delay(attempt, StatusCode::INTERNAL_SERVER_ERROR, &HeaderMap::new());
                    sleep(wait).await;
                    attempt += 1;
                    continue;
                }
                return Err(err).with_context(|| format!("{context} failed to send request"));
            }
        }
    }
}

fn should_retry(status: StatusCode, headers: &HeaderMap) -> bool {
    if status == StatusCode::TOO_MANY_REQUESTS {
        return true;
    }
    if status.is_server_error() {
        return true;
    }
    if status == StatusCode::FORBIDDEN {
        if let Some(remaining) = header_value(headers, "x-ratelimit-remaining")
            && remaining == "0" {
                return true;
            }
        if headers.get("retry-after").is_some() {
            return true;
        }
    }
    false
}

fn retry_delay(attempt: usize, status: StatusCode, headers: &HeaderMap) -> Duration {
    if let Some(secs) = retry_after_seconds(status, headers) {
        return Duration::from_secs(secs);
    }
    let backoff = RETRY_BASE_DELAY_MS.saturating_mul(2u64.saturating_pow(attempt as u32));
    Duration::from_millis(min(backoff, RETRY_MAX_DELAY_MS))
}

fn retry_after_seconds(status: StatusCode, headers: &HeaderMap) -> Option<u64> {
    if status == StatusCode::TOO_MANY_REQUESTS || status == StatusCode::FORBIDDEN {
        if let Some(value) = header_value(headers, "retry-after")
            && let Ok(secs) = value.parse::<u64>() {
                return Some(secs);
            }
        if let Some(value) = header_value(headers, "x-ratelimit-reset")
            && let Ok(epoch) = value.parse::<u64>() {
                let now = SystemTime::now()
                    .duration_since(UNIX_EPOCH)
                    .unwrap_or_default()
                    .as_secs();
                if epoch > now {
                    return Some(epoch - now);
                }
            }
    }
    None
}

fn header_value(headers: &HeaderMap, name: &str) -> Option<String> {
    headers
        .get(name)
        .and_then(|v| v.to_str().ok())
        .map(|s| s.to_string())
}

// REST API response types for commit search
#[derive(Debug, Deserialize)]
struct CommitSearchResponse {
    items: Vec<CommitSearchItem>,
}

#[derive(Debug, Deserialize)]
struct CommitSearchItem {
    commit: Option<CommitInfo>,
}

#[derive(Debug, Deserialize)]
struct CommitInfo {
    author: Option<CommitAuthor>,
}

#[derive(Debug, Deserialize)]
struct CommitAuthor {
    date: String,
}

/// Convert GitHub's contribution level string to a numeric level (0-4)
/// Implements [[RFC-0002:C-CONTRIBUTION-CALENDAR]]
fn level_from_string(level: &str) -> u8 {
    match level {
        "NONE" => 0,
        "FIRST_QUARTILE" => 1,
        "SECOND_QUARTILE" => 2,
        "THIRD_QUARTILE" => 3,
        "FOURTH_QUARTILE" => 4,
        _ => 0,
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use reqwest::header::HeaderValue;

    #[test]
    fn parse_timezone_offset_defaults_to_utc() {
        let offset = parse_timezone_offset(Some("invalid"));
        assert_eq!(offset.local_minus_utc(), 0);
    }

    #[test]
    fn parse_timezone_offset_parses_valid() {
        let offset = parse_timezone_offset(Some("+08:00"));
        assert_eq!(offset.local_minus_utc(), 8 * 3600);
    }

    #[test]
    fn merge_repository_page_appends_nodes() {
        let mut target = RepositoriesNode {
            total_count: 1,
            nodes: vec![RepoStatsNode {
                stargazer_count: 1,
                fork_count: 2,
            }],
            page_info: PageInfoNode {
                has_next_page: true,
                end_cursor: Some("cursor".to_string()),
            },
        };

        let page = RepositoriesNode {
            total_count: 2,
            nodes: vec![RepoStatsNode {
                stargazer_count: 3,
                fork_count: 4,
            }],
            page_info: PageInfoNode {
                has_next_page: false,
                end_cursor: None,
            },
        };

        merge_repository_page(&mut target, page);
        assert_eq!(target.total_count, 2);
        assert_eq!(target.nodes.len(), 2);
        assert!(!target.page_info.has_next_page);
    }

    #[test]
    fn retry_delay_prefers_retry_after() {
        let mut headers = HeaderMap::new();
        headers.insert("retry-after", HeaderValue::from_static("3"));
        let delay = retry_delay(0, StatusCode::TOO_MANY_REQUESTS, &headers);
        assert_eq!(delay.as_secs(), 3);
    }
}
